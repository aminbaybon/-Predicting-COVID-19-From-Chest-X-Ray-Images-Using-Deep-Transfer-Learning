{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet2 (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TXS3ikb1-j3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3291b64c-4fff-44f5-fa75-2091a8510976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import copy, pickle, os, time\n",
        "import argparse \n",
        "from google.colab import drive\n",
        "import random\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "from __future__ import print_function\n",
        "import torch, os, copy, time, pickle\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision.datasets.folder import IMG_EXTENSIONS\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import glob, pickle\n",
        "import seaborn as sn\n",
        "import argparse\n",
        "start_time= time.time()\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "from skimage.io import imread\n",
        "import PIL\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_unet = load_model('/content/gdrive/MyDrive/unet_30epochs.hdf5', compile=False)"
      ],
      "metadata": {
        "id": "R8AqSHXm2p-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train covid**"
      ],
      "metadata": {
        "id": "woQ-uQYOhNHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed=24\n",
        "batch_size= 420\n",
        "n_classes=2\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#Define a function to perform additional preprocessing after datagen.\n",
        "#For example, scale images, convert masks to categorical, etc. \n",
        "def preprocess_data(img):\n",
        "    img = img / 255. \n",
        "    return img\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def trainGenerator(train_img_path):\n",
        "    \n",
        "    img_data_gen_args = dict(horizontal_flip=True,\n",
        "                      vertical_flip=True,\n",
        "                      fill_mode='reflect')\n",
        "    \n",
        "    image_datagen = ImageDataGenerator(**img_data_gen_args)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_img_path,\n",
        "        class_mode = None,\n",
        "        color_mode = 'grayscale',\n",
        "        target_size=(128,128),\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    \n",
        "    \n",
        "    train_generator = image_generator\n",
        "    \n",
        "    for img in train_generator:\n",
        "        img2 = preprocess_data(img)\n",
        "        yield (img2)"
      ],
      "metadata": {
        "id": "r8F0EWUwka_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_path = '/content/gdrive/MyDrive/data2/train/covid'\n",
        "train_img_gen = trainGenerator(train_img_path)"
      ],
      "metadata": {
        "id": "P8zkHWUFCRRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_img_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmxtB9U8C1Si",
        "outputId": "c580fbc8-0e77-44d2-da8f-742ae5b407ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object trainGenerator at 0x7fd56c2b4ad0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_batch = train_img_gen.__next__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar4IAt2KDBZj",
        "outputId": "69c44f6b-273b-498e-dd82-b72491740c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 420 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_image_batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQZKiJ5MG02X",
        "outputId": "8eb26a86-0df8-4fb4-d482-7daa4541a14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "images66 = []\n",
        "for i in range(420):\n",
        "  test_img = train_image_batch[i]\n",
        "  test_img_norm=test_img[:,:,0][:,:,None]\n",
        "  test_img_input=np.expand_dims(test_img_norm, 0)\n",
        "  print(test_img_input.shape)\n",
        "  prediction = (model_unet.predict(test_img_input))\n",
        "  predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
        "  images66.append(predicted_img)"
      ],
      "metadata": {
        "id": "uTH6O4YnDMqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(images66))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BySODecODruF",
        "outputId": "5fda5358-6950-4478-f9fa-1c1375cc1d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(images66))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA8ztJ_oIgE1",
        "outputId": "4ccd7128-fb6d-4813-dd5b-539e9279f836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "i = 0\n",
        "for item in images66:\n",
        "  img_w, img_h = 128, 128\n",
        "  data = np.zeros((img_h, img_w,3), dtype=np.uint8)\n",
        "  data = item\n",
        "  img = Image.fromarray((data * 255).astype(np.uint8))\n",
        "  img.save('/content/gdrive/MyDrive/data3/train/covid/{}.png'.format(i))\n",
        "  time.sleep(0.2) \n",
        "  print(i)\n",
        "  i = i +1"
      ],
      "metadata": {
        "id": "ilhLcoYBIhur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/gdrive/MyDrive/data3/train/covid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w91PvN5I0SM",
        "outputId": "6df44264-96cc-4274-9cef-c914b99c7559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "420"
            ]
          },
          "metadata": {},
          "execution_count": 400
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train non covid**"
      ],
      "metadata": {
        "id": "t3ZXcdo0Jcho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed=24\n",
        "batch_size= 2000\n",
        "n_classes=2\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#Define a function to perform additional preprocessing after datagen.\n",
        "#For example, scale images, convert masks to categorical, etc. \n",
        "def preprocess_data(img):\n",
        "\n",
        "    img = img / 255. \n",
        "\n",
        "      \n",
        "    return img\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def trainGenerator(train_img_path):\n",
        "    \n",
        "    img_data_gen_args = dict(horizontal_flip=True,\n",
        "                      vertical_flip=True,\n",
        "                      fill_mode='reflect')\n",
        "    \n",
        "    image_datagen = ImageDataGenerator(**img_data_gen_args)\n",
        "\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_img_path,\n",
        "        class_mode = None,\n",
        "        color_mode = 'grayscale',\n",
        "        target_size=(128,128),\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "\n",
        "    \n",
        "    train_generator = image_generator\n",
        "    \n",
        "    for img in train_generator:\n",
        "        img2 = preprocess_data(img)\n",
        "        yield (img2)"
      ],
      "metadata": {
        "id": "KQQP3UIFI5bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_path = '/content/gdrive/MyDrive/data2/train/non'\n",
        "train_img_gen = trainGenerator(train_img_path)"
      ],
      "metadata": {
        "id": "VOan0-_KJeYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_batch = train_img_gen.__next__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe7ERY5DKlK1",
        "outputId": "19b3af24-298f-4b8d-dd9d-b2caaad0ec54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "images78 = []\n",
        "j = 0\n",
        "for i in range(2000):\n",
        "  j = j + 1\n",
        "  test_img = train_image_batch[i]\n",
        "\n",
        "  test_img_norm=test_img[:,:,0][:,:,None]\n",
        "  test_img_input=np.expand_dims(test_img_norm, 0)\n",
        "  print(j)\n",
        "  prediction = (model_unet.predict(test_img_input))\n",
        "  predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
        "  images78.append(predicted_img)\n"
      ],
      "metadata": {
        "id": "x2Bl338HKntE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(images78))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0_NNOaHKz56",
        "outputId": "56f94a54-1ad0-43d0-d0de-68555a1c1590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "i = 0\n",
        "for item in images78:\n",
        "  img_w, img_h = 128, 128\n",
        "  data = np.zeros((img_h, img_w,3), dtype=np.uint8)\n",
        "  data = item\n",
        "  img = Image.fromarray((data * 255).astype(np.uint8))\n",
        "  img.save('/content/gdrive/MyDrive/data3/train/non/non{}.png'.format(i))\n",
        "  time.sleep(0.2) \n",
        "  print(i)\n",
        "  i = i +1"
      ],
      "metadata": {
        "id": "UPVrTPhDQZLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test non covid**"
      ],
      "metadata": {
        "id": "lC3nHxQ9SmIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed=24\n",
        "batch_size= 3000\n",
        "n_classes=2\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#Define a function to perform additional preprocessing after datagen.\n",
        "#For example, scale images, convert masks to categorical, etc. \n",
        "def preprocess_data(img):\n",
        "    #Scale images\n",
        "    img = img / 255. \n",
        "\n",
        "      \n",
        "    return img\n",
        "\n",
        "#Define the generator.\n",
        "#We are not doing any rotation or zoom to make sure mask values are not interpolated.\n",
        "#It is important to keep pixel values in mask as 0, 1, 2, 3, .....\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def trainGenerator(train_img_path):\n",
        "    \n",
        "    img_data_gen_args = dict(horizontal_flip=True,\n",
        "                      vertical_flip=True,\n",
        "                      fill_mode='reflect')\n",
        "    \n",
        "    image_datagen = ImageDataGenerator(**img_data_gen_args)\n",
        "\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_img_path,\n",
        "        class_mode = None,\n",
        "        color_mode = 'grayscale',\n",
        "        target_size=(128,128),\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "\n",
        "    \n",
        "    train_generator = image_generator\n",
        "    \n",
        "    for img in train_generator:\n",
        "        img2 = preprocess_data(img)\n",
        "        yield (img2)"
      ],
      "metadata": {
        "id": "lwIbJ_KiQl9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_path = '/content/gdrive/MyDrive/data2/test/non'\n",
        "test_img_gen = trainGenerator(test_img_path)"
      ],
      "metadata": {
        "id": "_C1ISdqNSsI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_batch = test_img_gen.__next__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6LFKrJzTcRD",
        "outputId": "0ad9915f-032d-4194-a3bc-af1d7cb7487b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "images100 = []\n",
        "j = 0\n",
        "for i in range(3000):\n",
        "  j = j + 1\n",
        "  test_img = test_image_batch[i]\n",
        "\n",
        "  test_img_norm=test_img[:,:,0][:,:,None]\n",
        "  test_img_input=np.expand_dims(test_img_norm, 0)\n",
        "  print(j)\n",
        "  prediction = (model_unet.predict(test_img_input))\n",
        "  predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
        "  images100.append(predicted_img)\n",
        "\n"
      ],
      "metadata": {
        "id": "-L1VPoFATgap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(images100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwUKvBx-UL9r",
        "outputId": "41d98155-b9d4-4e1f-ee2d-f0759a355f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "i = 0\n",
        "for item in images100:\n",
        "  img_w, img_h = 128, 128\n",
        "  data = np.zeros((img_h, img_w,3), dtype=np.uint8)\n",
        "  data = item\n",
        "  img = Image.fromarray((data * 255).astype(np.uint8))\n",
        "  img.save('/content/gdrive/MyDrive/data3/test/non/non{}.png'.format(i))\n",
        "  time.sleep(0.2) \n",
        "  print(i)\n",
        "  i = i +1"
      ],
      "metadata": {
        "id": "13oX94jgT6rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test covid**"
      ],
      "metadata": {
        "id": "lE84-jFvZDS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed=24\n",
        "batch_size= 100\n",
        "n_classes=2\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#Define a function to perform additional preprocessing after datagen.\n",
        "#For example, scale images, convert masks to categorical, etc. \n",
        "def preprocess_data(img):\n",
        "    #Scale images\n",
        "    img = img / 255. \n",
        "\n",
        "      \n",
        "    return img\n",
        "\n",
        "#Define the generator.\n",
        "#We are not doing any rotation or zoom to make sure mask values are not interpolated.\n",
        "#It is important to keep pixel values in mask as 0, 1, 2, 3, .....\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def trainGenerator(train_img_path):\n",
        "    \n",
        "    img_data_gen_args = dict(horizontal_flip=True,\n",
        "                      vertical_flip=True,\n",
        "                      fill_mode='reflect')\n",
        "    \n",
        "    image_datagen = ImageDataGenerator(**img_data_gen_args)\n",
        "\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_img_path,\n",
        "        class_mode = None,\n",
        "        color_mode = 'grayscale',\n",
        "        target_size=(128,128),\n",
        "        batch_size = batch_size,\n",
        "        seed = seed)\n",
        "    \n",
        "\n",
        "    train_generator = image_generator\n",
        "    \n",
        "    for img in train_generator:\n",
        "        img2 = preprocess_data(img)\n",
        "        yield (img2)"
      ],
      "metadata": {
        "id": "ieiVVleqUNSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_path = '/content/gdrive/MyDrive/data2/test/covid'\n",
        "test_img_gen = trainGenerator(test_img_path)"
      ],
      "metadata": {
        "id": "a8tBMJzAZLK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_batch = test_img_gen.__next__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51FRm-JmZg60",
        "outputId": "4509fdc4-131c-47a4-be30-ca481654489e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "images200 = []\n",
        "j = 0\n",
        "for i in range(100):\n",
        "  j = j + 1\n",
        "  test_img = test_image_batch[i]\n",
        "  test_img_norm=test_img[:,:,0][:,:,None]\n",
        "  test_img_input=np.expand_dims(test_img_norm, 0)\n",
        "  print(j)\n",
        "  prediction = (model_unet.predict(test_img_input))\n",
        "  predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
        "  images200.append(predicted_img)\n",
        "\n"
      ],
      "metadata": {
        "id": "VatOvjvxZj21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(images200))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93p5T_58duUg",
        "outputId": "6ad70437-83b0-440f-e55f-2a390894c843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "i = 0\n",
        "for item in images200:\n",
        "  img_w, img_h = 128, 128\n",
        "  data = np.zeros((img_h, img_w,3), dtype=np.uint8)\n",
        "  data = item\n",
        "  img = Image.fromarray((data * 255).astype(np.uint8))\n",
        "  img.save('/content/gdrive/MyDrive/data3/test/covid/{}.png'.format(i))\n",
        "  time.sleep(0.2) \n",
        "  print(i)\n",
        "  i = i +1"
      ],
      "metadata": {
        "id": "rlbauBiDdyw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check**"
      ],
      "metadata": {
        "id": "OXAL46x5DqdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/content/gdrive/MyDrive/data3/train/covid')))\n",
        "print(len(os.listdir('/content/gdrive/MyDrive/data3/train/non')))\n",
        "print(len(os.listdir('/content/gdrive/MyDrive/data3/test/covid')))\n",
        "print(len(os.listdir('/content/gdrive/MyDrive/data3/test/non')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsR_FXFxd-Fr",
        "outputId": "51d7bd76-58e9-4cec-dd90-649dfa1825a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420\n",
            "2000\n",
            "100\n",
            "3000\n"
          ]
        }
      ]
    }
  ]
}